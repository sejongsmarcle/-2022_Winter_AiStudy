{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "for test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 신경망의 구현 과정\n",
        "***1*** | **환경 변수 지정**:  데이터셋(입력 값, 결괏값),\n",
        "     학습률, 활성화 함수, 가중치 포함.\n",
        "<br>\n",
        "***2*** | **신경망 실행**: 초기값 입력 -> 활성화 함수, 가중치 -> 결과값\n",
        "<br>\n",
        "***3*** | **결과를 실제 값과 비교**: 오차 측정\n",
        "<br>\n",
        "***4*** | **역전파 실행**: 출력층, 은닉층의 가중치 수정\n",
        "<br>\n",
        "***5*** | **결과 출력**"
      ],
      "metadata": {
        "id": "tiT1EP1ApiVt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. 라이브러리 import"
      ],
      "metadata": {
        "id": "AfqGLCGrplPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "random.seed(777) # 시드: 난수 생성기를 초기화해주는 역할\n",
        "\n",
        "#num_x=2+1\n",
        "#num_yh=2\n",
        "#num_yo=1\n",
        "\n",
        "#input=[1.0]*num_x\n",
        "#hidden=[1.0]*num_yh\n",
        "#out=[1.0]*num_yo\n",
        "\n",
        "#fill=0.0\n",
        "#weight_in = []\n",
        "#for i in range(num_x):\n",
        "#  weight_in.append([fill]*num_yh)\n",
        "\n",
        "#for i in range(num_x):\n",
        "#        for j in range(num_yh):\n",
        "#          weight_in[i][j] = random.random()\n",
        "\n",
        "#weight_in"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GpMu3Dx2m2af",
        "outputId": "2629f06f-d537-470b-b7bc-2ad6b39b2db3"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.22933408950153078, 0.44559617334521107],\n",
              " [0.36859824937216046, 0.269835098321503],\n",
              " [0.3361436466700177, 0.7523163560031157]]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 환경 변수 설정하기\n",
        "\n",
        "### XOR 진리표\n",
        "| x1 | X2 | 결괏값 |\n",
        "| --- | --- | --- | \n",
        "| 0 | 0 | 0 |\n",
        "| 0 | 1 | 1 |\n",
        "| 1 | 0 | 1 |\n",
        "| 1 | 1 | 0 |"
      ],
      "metadata": {
        "id": "WHNYBW1Viwdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 값, 타깃 값\n",
        "# 입력 값은 진리표의 x1, x2\n",
        "# 타깃 값은 정답 데이터(yt)\n",
        "\n",
        "data = [\n",
        "        [[0,0],[0]],\n",
        "        [[0,1],[1]],\n",
        "        [[1,0],[1]],\n",
        "        [[1,1],[0]]\n",
        "]\n",
        "\n",
        "# 실행 횟수(iterations), 학습률(lr), 모멘텀 계수(mo) 설정\n",
        "iterations = 5000\n",
        "lr = 0.1\n",
        "mo = 0.4\n",
        "\n",
        "# 활성화 함수, 초기 가중치 지정\n",
        "# 활성화 함수 1. 시그모이드\n",
        "def sigmoid(x, derivative = False):\n",
        "  if (derivative == True):\n",
        "    return x*(1-x)  # 미분할 때의 값\n",
        "  return 1/(1+np.exp(-x)) # 미분하지 않을 때의 값\n",
        "\n",
        "# 활성화 함수 2. tanh(하이퍼볼릭 탄젠트)\n",
        "def tanh(x, derivative=False):\n",
        "  if (derivative == True):\n",
        "    return 1-x**2 # 미분할 때의 값: 1-(출력의 제곱)\n",
        "  return np.tanh(x)\n",
        "\n",
        "# 가중치 배열을 만드는 함수\n",
        "def makeMatrix(i,j,fill=0.0): # i개 행 j개 열(i×j)\n",
        "  mat = []\n",
        "  for i in range(i):\n",
        "    mat.append([fill]*j)\n",
        "  return  mat"
      ],
      "metadata": {
        "id": "w9sxbpTzjgh0"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 신경망의 실행\n",
        "신경망을 실행하는 클래스는\n",
        "- 초깃값의 지정(입력값,은닉층의 초깃값, 출력층의 초깃값, 바이어스, 활성화 함수와 가중치 초깃값)\n",
        "- 업데이트 함수(optimizer 선택 가능 -> 모멘텀 SGD)\n",
        "- 역전파 함수\n",
        "로 구성된다."
      ],
      "metadata": {
        "id": "b7LZsbg9lST1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 신경망의 실행\n",
        "class NeuralNetwork:\n",
        "\n",
        "    # 초깃값 지정\n",
        "    def __init__(self, num_x, num_yh, num_yo, bias=1):\n",
        "\n",
        "      # 입력 값(num_x), 은닉층의 초깃값(num_yh), 출력층의 초깃값(num_yo), 바이어스\n",
        "      self.num_x = num_x + bias # 바이어스는 1로 설정\n",
        "      ### Q. 왜 여기에 bias를 더함?\n",
        "      self.num_yh = num_yh\n",
        "      self.num_yo = num_yo\n",
        "\n",
        "      # 활성화 함수 초깃값\n",
        "      self.activation_input = [1.0]*self.num_x\n",
        "      self.activation_hidden = [1.0]*self.num_yh\n",
        "      self.activation_out = [1.0]*self.num_yo\n",
        "\n",
        "      # 가중치 입력 초깃값\n",
        "      self.weight_in = makeMatrix(self.num_x, self.num_yh)  # 입력값 개수만큼의 행, 레이어 개수만큼의 열 -> 행열\n",
        "      for i in range(self.num_x):\n",
        "        for j in range(self.num_yh):\n",
        "          self.weight_in[i][j] = random.random()\n",
        "\n",
        "      # 가중치 출력 초깃값\n",
        "      self.weight_out = makeMatrix(self.num_yh,self.num_yo) # 레이어 개수만큼의 행, 출력값 개수만큼의 열 -> 행열\n",
        "      for j in range(self.num_yh):\n",
        "        for k in range(self.num_yo):\n",
        "          self.weight_out[j][k] = random.random()\n",
        "\n",
        "      # 모멘텀 SGD를 위한 이전 가중치 초깃값\n",
        "      self.gradient_in = makeMatrix(self.num_x, self.num_yh)\n",
        "      self.gradient_out = makeMatrix(self.num_yh, self.num_yo)\n",
        "\n",
        "\n",
        "\n",
        "    # 업데이트 함수\n",
        "    def update(self, inputs):\n",
        "\n",
        "      # 입력층의 활성화 함수\n",
        "      for i in range(self.num_x-1):\n",
        "        self.activation_input[i]=inputs[i]\n",
        "\n",
        "      # 은닉층의 활성화 함수\n",
        "      for j in range(self.num_yh):\n",
        "        sum=0.0\n",
        "        for i in range(self.num_x):\n",
        "          sum+=self.activation_input[i]*self.weight_in[i][j]\n",
        "        # 시그모이드와 tanh 중에서 활성화 함수 선택\n",
        "        self.activation_hidden[j]=tanh(sum, False) \n",
        "\n",
        "      # 출력층의 활성화 함수\n",
        "      for k in range(self.num_yo):\n",
        "        sum = 0.0\n",
        "        for j in range(self.num_yh):\n",
        "          sum += self.activation_hidden[j]*self.weight_out[j][k]\n",
        "        # 시그모이드와 tanh 중에서 활성화 함수 선택\n",
        "        self.activation_out[k]=tanh(sum, False) \n",
        "\n",
        "      return self.activation_out[:]\n",
        "\n",
        "\n",
        "    # 역전파 실행\n",
        "  \n",
        "    def backPropagate(self, targets):\n",
        "    \n",
        "      # 델타 출력 계산\n",
        "      output_deltas = [0.0]*self.num_yo\n",
        "      for k in range(self.num_yo):\n",
        "        error = targets[k] - self.activation_out[k]\n",
        "        # 시그모이드와 tanh 중에서 활성화 함수 선택, 미분 적용\n",
        "        output_deltas[k] = tanh(self.activation_out[k],True)*error\n",
        "      \n",
        "      # 은닉 노드의 오차 함수\n",
        "      hidden_deltas = [0.0]*self.num_yh\n",
        "      for j in range(self.num_yh):\n",
        "        error=0.0\n",
        "        for k in range(self.num_yo):\n",
        "          error += output_deltas[k]*self.weight_out[j][k]\n",
        "          # 시그모이드와 tanh 중에서 활성화 함수 선택, 미분 적용\n",
        "          hidden_deltas[j] = tanh(self.activation_hidden[j],True)*error\n",
        "\n",
        "      # 출력 가중치 업데이트\n",
        "      for j in range(self.num_yh):\n",
        "        for k in range(self.num_yo):\n",
        "          gradient = output_deltas[k]*self.activation_hidden[j]\n",
        "          v = mo*self.gradient_out[j][k] - lr*gradient\n",
        "          self.weight_out[j][k] += v\n",
        "          self.gradient_out[j][k] = gradient\n",
        "\n",
        "      # 입력 가중치 업데이트\n",
        "      for i in range(self.num_x):\n",
        "        for j in range(self.num_yh):\n",
        "          gradient = hidden_deltas[j]*self.activation_input[i]\n",
        "          v = mo*self.gradient_in[i][j]-lr*gradient\n",
        "          self.weight_in[i][j]+= v\n",
        "          self.gradient_in[i][j]= gradient\n",
        "\n",
        "      # 오차 계산(최소 제곱법)\n",
        "      error = 0.0\n",
        "      for k in range(len(targets)):\n",
        "        error +=0.5*(targets[k]-self.activation_out[k])**2\n",
        "      return error\n",
        "\n",
        "  # 학습 실행\n",
        "    def train(self, patterns):\n",
        "      for i in range(iterations):\n",
        "        error = 0.0\n",
        "        for p in patterns:\n",
        "          inputs = p[0]\n",
        "          targets = p[1]\n",
        "          self.update(inputs)\n",
        "          error += self.backPropagate(targets)\n",
        "        if i%500 == 0:\n",
        "          print('error: %-.5f' %error)\n",
        "\n",
        "  # 결괏값 출력\n",
        "    def result(self, patterns):\n",
        "      for p in patterns:\n",
        "        print('Input: %s, Predict: %s -> %s' %(p[0],self.update(p[0]),np.round(self.update(p[0]),1)))\n"
      ],
      "metadata": {
        "id": "2RFfsS1QlKnI"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 학습 실행시키고 결괏값 출력"
      ],
      "metadata": {
        "id": "qaGdDCot3jHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if __name__ == '__main__':\n",
        "  # 두 개의 입력값, 두 개의 레이어, 하나의 출력값 갖도록 설정\n",
        "  n = NeuralNetwork(2,2,1)\n",
        "\n",
        "  # 학습 실행\n",
        "  n.train(data)\n",
        "\n",
        "  # 결괏값 출력\n",
        "  n.result(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1S1_H1lg1VUy",
        "outputId": "0a7e196b-ac08-4bbe-9b5a-372f88b1c41f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error: 0.48996\n",
            "error: 0.00269\n",
            "error: 0.00089\n",
            "error: 0.00051\n",
            "error: 0.00036\n",
            "error: 0.00027\n",
            "error: 0.00022\n",
            "error: 0.00019\n",
            "error: 0.00016\n",
            "error: 0.00014\n",
            "Input: [0, 0], Predict: [0.0005987966863271798] -> [0.]\n",
            "Input: [0, 1], Predict: [0.9889458320792305] -> [1.]\n",
            "Input: [1, 0], Predict: [0.9889765087616103] -> [1.]\n",
            "Input: [1, 1], Predict: [0.0021738653536299353] -> [0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UnbhG17z50ID"
      },
      "execution_count": 32,
      "outputs": []
    }
  ]
}