# 🌟모델 성능을 높이기 위해 시도할 수 있는 방법들

## Ⅰ. 데이터 조작하기
### 1. 데이터 스케일링
모델에 데이터를 넣을 때, feature 마다 데이터의 범위가 제각각이면 중요도가 달라지기 때문에 모델이 예측을 제대로 하는 것이 불가능합니다.   
이런 이유로 데이터를 모델에 넣기 전에 스케일링하는 과정이 필요합니다. 스케일링(scaling)이란 모델에 사용할 데이터의 feature들의 범위를 통일시키는 작업을 말합니다.   
데이터를 스케일링하는 데 사용되는 개념은 주로 두 가지입니다. 바로 Standardization(표준화)와 Normalization(정규화)입니다.
- 표준화: feature마다 갖고 있는 데이터의 평균을 0, 분산을 1로 바꿉니다. 즉, 데이터를 정규분포로 만듭니다.
- 정규화: feature마다 갖고 있는 데이터의 범위가 한정되도록 바꿉니다. ex. [0,1] (0에서 1 사이의 값만 갖게 됨)


#### ✔ 예시
scikit-learn에서 여러가지 스케일링 함수를 제공하는데, 데이터의 상황에 따라 적절한 스케일러를 도입해보며 성능을 향상시켜 봅시다.
- StandardScaler(): 데이터를 정규분포로 만든다. 분류에 주로 사용.
- MinMaxScalar(): 데이터를 특정 범위([0,1])로 만든다. 회귀에 주로 사용.
- MaxAbsScaler(): 데이터를 특정 범위([-1,1])로 만든다. 
- RobustScaler(): 평균과 분산 대신에 중간 값과 사분위 값을 사용하여 튀는 데이터(이상치)에 의한 오차를 개선할 수 있다.
- Normalizer()


#### ✔ 참고
- [데이터 스케일리의 개념과 5가지 scikit-learn scaler 함수](https://wooono.tistory.com/96)

### 2. 튀는 데이터 살펴보기
데이터의 경향성에 어긋나는 데이터는 데이터를 흔히 튀는 데이터, 즉 이상치(outlier)라고 표현합니다. 데이터에 이상치가 있나 살펴보고 이를 조작하면 모델의 성능을 좀 더 개선할 수 있습니다. 데이터를 시각화해서 확인해서 이상치가 있나 점검해보세요.

### 3. 사용할 feature만 선택하기]







- 더 자세한 설명은 아래의 포스트를 참고하세요!
https://machinelearningmastery.com/improve-deep-learning-performance/
