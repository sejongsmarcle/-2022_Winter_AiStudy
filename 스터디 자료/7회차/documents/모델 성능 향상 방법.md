# 모델 성능을 높여보자!🎈
`좋은 인공지능 모델`이란 무엇일까요? <br>
당연히 train set을 벗어난 **완전히 새로운 데이터의 결과도 알맞게 예측할 수 있는 모델**일 것입니다. 그러기 위해서 개발자들은 아래의 두 가지를 고려하면서 모델의 예측 정확도를 높일 수 있어야 합니다.<br>
1. 모델이 기존 데이터에 `underfitting/overfitting` 되지 않아야 한다.
2. 모델이 새로운 데이터에 유연히 대처할 수 있도록 충분히 `일반화(generalization)` 되어야 한다. <br>

사실 이 둘은 어찌보면 같은 맥락 상에 있습니다. 그렇다면 모델의 성능을 높이기 위해 어떤 것들을 시도해볼 수 있을까요? <br>

1. `데이터 조작`
2. `알고리즘 튜닝` 
3. 여러가지 알고리즘 혼합한 `앙상블` <br>

크게 세 가지 방향으로 모델 성능을 개선할 수 있습니다. 일반적으로는 `데이터 조작`이 모델 성능에 가장 큰 영향을 주고 번호 순으로 그 영향이 작아집니다. <br>
<br>
[How To Improve Deep Learning Performance](https://machinelearningmastery.com/improve-deep-learning-performance/) 포스트를 기반으로 , `AI study 수업 시간에 다루어 본 방법들`을 추려 소개해보려 합니다. <br>
<br>
그럼 차례대로 각각 어떤 방법을 사용해볼 수 있나 살펴보겠습니다.

## Ⅰ. 데이터 조작
### ⅰ. 데이터 스케일링
모델에 데이터를 넣을 때, feature 마다 데이터의 범위가 제각각이라면 feature 마다 결과 값에 행사하는 영향력이 달라지기 때문에 모델이 예측을 제대로 하는 것이 불가능합니다. 이런 이유로 **데이터를 모델에 넣기 전에 스케일링하는 과정**이 필요합니다. <br>
`스케일링(scaling)`이란 **모델에 사용할 데이터의 feature들의 범위를 통일시키는 작업**을 말합니다. feature 마다 다른 데이터의 단위를 서로 비교 가능하게 변환해주는 것입니다. 데이터를 스케일링하는 데 사용되는 개념은 주로 두 가지입니다. 바로 `Standardization(표준화)`와 `Normalization(정규화)`입니다.
- `Standardization(표준화)`: feature 마다 갖고 있는 데이터의 평균을 0, 분산을 1로 바꿉니다. 즉, 데이터를 정규분포로 만듭니다.
- `Normalization(정규화)`: feature 마다 갖고 있는 데이터의 범위가 한정되도록 바꿉니다. ex. [0,1] (0에서 1 사이의 값만 갖게 됨) <br>
![image](https://user-images.githubusercontent.com/78032658/152022273-75363d5d-46e3-4d8f-9971-59dd60e86691.png)



#### ✔ 예시
scikit-learn에서 여러가지 스케일링 함수를 제공하는데, 데이터의 상황에 따라 적절한 스케일러를 도입해보며 성능을 향상시켜 봅시다.
- `StandardScaler()`: 데이터를 정규분포로 만든다. 분류에 주로 사용.
- `MinMaxScalar()`: 데이터를 특정 범위([0,1])로 만든다. 회귀에 주로 사용.
- `MaxAbsScaler()`: 데이터를 특정 범위([-1,1])로 만든다. 
- `RobustScaler()`: 평균과 분산 대신에 중간 값과 사분위 값을 사용하여 튀는 데이터(이상치)에 의한 오차를 개선할 수 있다.
- `Normalizer()` <br>


#### ✔ 참고
- [데이터 스케일리의 개념과 5가지 scikit-learn scaler 함수](https://wooono.tistory.com/96) <br>

### ⅱ. 튀는 데이터 살펴보기
데이터의 경향성에 어긋나는 데이터를 흔히 튀는 데이터, 즉 `이상치(outlier)`라고 표현합니다. <br>
데이터에 이상치가 있나 살펴보고 조작하면 모델의 성능을 개선할 수 있습니다. `데이터 시각화`를 하면 이상치를 시각 자료로 확인할 수 있습니다. <br>
<br>


## Ⅱ. 알고리즘 튜닝
환자가 아파서 병원에 가면 의사 선생님이 무턱대로 약을 처방해주지는 않습니다. 그 전에 진단이 필요하죠. <br>
마찬가지로 골골대는 우리의 모델을 치료해주기 위해서는 그 원인을 진단해야 합니다. 즉, 모델의 `성능 값을 모니터링`하고 이를 기반으로 상태를 `분석`할 수 있어야 합니다. <br>
<br>
이때 train set의 정확도와 test(val) set의 정확도를 모니터링 및 분석하여 `underfitting` 상태인지 `overfitting` 상태인지 판단할 수 있습니다.<br>
  - train set과 test(val) set 에서 모두 정확도가 낮다. -> `underfitting`
  - train set에 비해 test(val) set에서 정확도가 낮다. -> `overfitting` <br>
  ![image](https://user-images.githubusercontent.com/78032658/152030055-c8304471-313f-4cc6-8864-4bec9cffb37b.png)


현재 모델의 상태 분석을 완료했다면 그 문제를 해결하기 위한 방법들을 알아봅시다.<br>
<br>
### ⅰ. 학습률(Learning Rate)
여러 번 모델을 돌려보고 사용 중인 데이터/파라미터/환경 등에 적절한 learning rate를 찾아야 합니다. <br>

### ⅱ. 활성화 함수(Activation Functions)
적절한 activation function을 사용하고 있는지 점검해봅니다. <br>
일반적으로 어떤 알고리즘에 따라 적절하게 사용해야 하는 activation function은 한정적으로 정해져있기 때문에 모델의 각 layer 상황에 맞는 activation function을 설정해줘야 합니다.


#### ✔ 참고
[활성화 함수(activation function)종류와 장단점에 따른 쓰임 정리](https://ganghee-lee.tistory.com/32)


![image](https://user-images.githubusercontent.com/78032658/152031297-781f3e3c-4ff4-4c0b-95dc-860e7522afb2.png)


## Plus!✌ 파라미터(Parameter) vs. 하이퍼 파라미터(Hyper parameter)
`파라미터(Parameter)`와 `하이퍼 파라미터(Hyper parameter)`는 다른 개념입니다.
- `파라미터(Parameter)`
  - 모델이 학습되며 모델 내부에서 결정되는 변수
  - 가중치(weight)와 편향(bias) 등이 해당
- `하이퍼 파라미터(Hyper parameter)`
  - 모델링할 때 사용자가 직접 값을 설정해주는 변수
  - 학습률(learning rate), 에포크(epoch), iteration 등이 해당
  - 정해진 최적의 값이 없기 때문에 경험으로 결정된다.
  - 자동으로 하이퍼 파라미터를 정해주는 라이브러리 사용할 수 있다. ex. 베이지안 옵티미제이션 <br>

[하이퍼파라미터 튜닝 팁](https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/)
